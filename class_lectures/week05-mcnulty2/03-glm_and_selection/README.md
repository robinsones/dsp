### Schedule

**9:00 am**: Sun salutations

**9:15 am**: [Pair Problem](pair.md)

**10:00 am**: [Generalized Linear Models](GLMs.pdf)

 * [Notes on GLMs](GLM_notes.md)
 * [Various ways to do logistic regression (notebook)](GLM_examples.ipynb)

**11:00 am**: Mid-McNulty design status sharing!

**12:00pm**: Food!

**1:30 pm**: Investigation Presentation


### Further Resources

GLMs:

 * [Generalized Linear Models in detail](http://www.sagepub.com/upm-data/21121_Chapter_15.pdf)
 * [Generalized Linear Models slides](http://statmath.wu.ac.at/courses/heather_turner/glmCourse_001.pdf)
 * [Generalized Linear Models in Wikipedia](http://en.wikipedia.org/wiki/Generalized_linear_model)


Feature selection:

 * [Forward selection with statsmodels](http://planspace.org/20150423-forward_selection_with_statsmodels/)
 * [sklearn feature selection](http://scikit-learn.org/stable/modules/feature_selection.html)
 * [Chi square feature selection](http://blog.datumbox.com/using-feature-selection-methods-in-text-classification/)
 * [Feature selection criteria](http://blog.datumbox.com/using-feature-selection-methods-in-text-classification/)
 * [Variable Selection is Hard](http://arxiv.org/abs/1412.4832), a paper by Dean Foster, Howard Karloff, and Justin Thaler, which proves the title
