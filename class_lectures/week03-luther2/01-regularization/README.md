### Schedule

**9:00 am**: Preparing with coffee.

**9:15 am**: [Pair Problem](pair.md)

**10:00 am**: [Regularization](regularization.pdf)

**12:00 pm**: Lunch!

**1:30 pm**: Investigation Presentation

**1:45 pm**: Best projects ever!


### Further Reading

 * [Regularized Linear Regression with scikit learn](http://www.datarobot.com/blog/regularized-linear-regression-with-scikit-learn/): This goes over some of the theory we discussed, and shows using regularization on an actual scikit learn example. It uses Lasso instead of Ridge. The only difference between Lasso and Ridge regularization is this: Ridge adds sum of beta squares to the cost, Lasso adds sum of beta absolute values. Other than that functional form, the idea is pretty much the same. The interface of using LinearRegression() or Ridge(alpha) or Lasso(alpha) is also exactly the same.
 * [Ten minute video lecture on regularization](https://www.youtube.com/watch?v=fx-TqOzjDbM): Another ten minute lecture by Andrew Ng on how the cost function manipulation works in regularization. It helps build intuition.
