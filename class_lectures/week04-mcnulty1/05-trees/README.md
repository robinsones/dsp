### Schedule

**9:00 am**: Coffee in the morning

**9:15 am**: [Pair Problem](pair.md)

**10:00 am**: [Decision Trees and Random Forests](Decision_Trees_Random_Forests.pdf)

**12:00pm**: Lunch

**1:30 pm**: Investigation Presentation

**1:45 pm**: Work Time


### Reading

 * [Rutgers decision tree lecture](http://www.cs.rutgers.edu/~mlittman/courses/ml04/ch3.pdf) (some of our slides are based on this)
 * [Wisconsin decision tree lecture](http://pages.cs.wisc.edu/~jerryzhu/cs540/handouts/dt.pdf) (similar, more examples)
 * [Decision trees in sklearn](http://scikit-learn.org/stable/modules/tree.html) (including demo showing how to examine generated rules)
 * [Wikipedia entry on random forests](http://en.wikipedia.org/wiki/Random_forest)
 * [Wikipdia entry including information entropy](http://en.wikipedia.org/wiki/Entropy_%28information_theory%29)
 * [Using Python to build a decision tree from scratch](http://nbviewer.ipython.org/github/gumption/Python_for_Data_Science/blob/master/4_Python_Simple_Decision_Tree.ipynb)
 * A [notebook](http://nbviewer.ipython.org/gist/rcarneva/261dd7baa4a4a2a8bf2b) demonstrating gradient boosted trees, among other things.
