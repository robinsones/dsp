{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Set 6\n",
    "Topic: Decision Trees<br>\n",
    "Date: 08/16/2016<br>\n",
    "Name: Seth Kaufman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.grid_search  import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree / Forest Challenges\n",
    "\n",
    "You can examine the decision paths of an `sklearn` tree by generating `pydot` graphs as in the `sklearn` [documentation](http://scikit-learn.org/stable/modules/tree.html). It's sometimes tricky to get `pydot` working; see below for a possible install plan.\n",
    "\n",
    "\n",
    "#### Challenge 1\n",
    "\n",
    "For the house representatives data set, fit and evaluate a decision tree classifier. Examine the rules your tree uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../challenges_data/house-votes-84.data\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../challenges_data/house-votes-84.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hv = pd.read_csv('/Users/Seth/Documents/Data Science/Metis/nyc16_ds8/challenges/challenges_data/house-votes-84.data',\n",
    "                 header=-1,na_values='?')\n",
    "hv.replace({'y':1,'n':0},inplace=True)\n",
    "hv[16]=hv[16].apply(lambda x : ''.join([i for i in x if i.isalpha()]))\n",
    "hv = hv.fillna(hv.mean(axis=0))\n",
    "y = hv[16]\n",
    "X = hv.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=10, min_samples_leaf=2,\n",
       "            min_samples_split=4, min_weight_fraction_leaf=0.5,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval=StratifiedShuffleSplit(y,test_size=.3)\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
    "            max_features=None, max_leaf_nodes=10, min_samples_leaf=2,\n",
    "            min_samples_split=4, min_weight_fraction_leaf=0.5,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "dt.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " tree.export_graphviz(dt,out_file='hv.dot',feature_names=X.columns,class_names=y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!dot -Tsvg hv.dot -o hv.svg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='hv.svg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 2\n",
    "\n",
    "Fit and evaluate a decision tree classifier for your movie dataset. Examine the rules your tree uses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mojo = pd.read_csv('/Users/Seth/Documents/Data Science/Metis/nyc16_ds8/challenges/challenges_data/2013_movies.csv',\n",
    "                   parse_dates=['ReleaseDate'],infer_datetime_format=True)\n",
    "mojo['ReleaseDate'] = mojo['ReleaseDate'].dt.month\n",
    "mojo['Budget'] = mojo['Budget'].fillna(mojo['Budget'].mean(axis=0))\n",
    "predictors = mojo[\n",
    "    [#'Title',\n",
    "     'Budget',\n",
    "     'DomesticTotalGross',\n",
    "     #'Director',\n",
    "     'Runtime',\n",
    "     'ReleaseDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.476244  ,  0.        ,  0.29609394,  0.22766206])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(predictors)\n",
    "y = (mojo['Rating'].factorize()[0]==0).astype(int)\n",
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
    "            max_features=None, max_leaf_nodes=8, min_samples_leaf=2,\n",
    "            min_samples_split=4, min_weight_fraction_leaf=0.5, splitter='best')\n",
    "dt.fit(X,y)\n",
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(dt,out_file='mojo.dot',feature_names=predictors.columns,class_names=mojo['Rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!dot -Tsvg mojo.dot -o mojo.svg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='mojo.svg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 3 (Optional but recommended)\n",
    "\n",
    "Tackle the [Titanic Survivors kaggle competition](https://www.kaggle.com/c/titanic-gettingStarted) with decision trees. Look at your splits; how does your tree decide?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score,roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train['Age'].fillna(train['Age'].mean(),inplace=True)\n",
    "train['Embarked'].fillna('S',inplace=True)\n",
    "train['fam'] = train.Parch + train.SibSp\n",
    "predictors = [#'PassengerId',\n",
    "              #'Survived', \n",
    "              'Pclass', \n",
    "              #'Name', \n",
    "              'Sex',\n",
    "              'Age', \n",
    "              #'SibSp',\n",
    "                #'Parch', \n",
    "              #'Ticket',\n",
    "              'Fare', \n",
    "              #'Cabin',\n",
    "              'Embarked',\n",
    "              'fam']\n",
    "\n",
    "X = pd.get_dummies(train[predictors])\n",
    "X.iloc[:,:3] = scale(X.iloc[:,:3])\n",
    "y=train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87985141381315923"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(y, n_iter=10,test_size=.2)\n",
    "for train_index, test_index in sss:\n",
    "    xtrain, xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    ytrain, ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "param_test1 = {'n_estimators':list(range(1,300,20))}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                        min_samples_split=4,min_samples_leaf=4,\n",
    "                                        max_depth=3,max_features='sqrt',subsample=0.8), \n",
    "                                        param_grid = param_test1, scoring='roc_auc',n_jobs=10,iid=False, cv=4)\n",
    "gsearch1.fit(xtrain,ytrain)\n",
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3, 'min_samples_split': 30}, 0.8775723251189006)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth':list(range(1,10,1)), 'min_samples_split':list(range(10,300,10))}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=180, \n",
    "                                            max_features='sqrt', subsample=0.8), \n",
    "                                            param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=4)\n",
    "gsearch2.fit(xtrain,ytrain)\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'min_samples_leaf': 32, 'min_samples_split': 130}, 0.87567135772066385)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_split':list(range(50,300,10)), 'min_samples_leaf':list(range(2,100,5))}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=180,max_depth=8,\n",
    "                                                max_features='sqrt', subsample=0.8, random_state=10), \n",
    "                                                param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=4)\n",
    "gsearch3.fit(xtrain,ytrain)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_features': 1}, 0.88147513166342795)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':list(range(1,9,1))}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=41,max_depth=8, \n",
    "                                            min_samples_split=160, min_samples_leaf=7, \n",
    "                                            subsample=0.8),\n",
    "                                            param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=4)\n",
    "gsearch4.fit(xtrain,ytrain)\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'subsample': 0.75}, 0.87792172336353047)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=41,max_depth=8, \n",
    "                                            min_samples_split=100, min_samples_leaf=2, \n",
    "                                            subsample=0.9,max_features =5),\n",
    "                                            param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=4)\n",
    "gsearch5.fit(xtrain,ytrain)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853301260783\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86       220\n",
      "          1       0.78      0.75      0.77       137\n",
      "\n",
      "avg / total       0.82      0.82      0.82       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(y, n_iter=10,test_size=.4)\n",
    "for train_index, test_index in sss:\n",
    "    xtrain, xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    ytrain, ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=1000,max_depth=8, \n",
    "                                            min_samples_split=20, min_samples_leaf=2, \n",
    "                                            subsample=0.9,max_features =9 )\n",
    "gbm_tuned_1.fit(xtrain,ytrain)\n",
    "print(roc_auc_score(ytest,gbm_tuned_1.predict_proba(xtest)[:,1]))\n",
    "print(classification_report(ytest,gbm_tuned_1.predict(xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing pydot for the challenges:\n",
    "\n",
    "Note: Uninstall pydot if you already installed it but it's not working\n",
    "\n",
    "    pip uninstall pydot\n",
    "\n",
    "Otherwise, you can start here:\n",
    "\n",
    "    pip uninstall pyparsing\n",
    "\n",
    "    pip install -Iv\n",
    "    https://pypi.python.org/packages/source/p/pyparsing/pyparsing-1.5.7.tar.gz#md5=9be0fcdcc595199c646ab317c1d9a709\n",
    "\n",
    "    pip install pydot\n",
    "\n",
    "    brew install graphviz\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
