{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pickle.load(open('df_dsmpl_orginal_charged_50.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'date', 'manner_of_death', 'armed', 'age', 'gender',\n",
       "       'race', 'city', 'state', 'signs_of_mental_illness', 'threat_level',\n",
       "       'flee', 'body_camera', 'age_right', 'armed_right', 'blurb',\n",
       "       'description', 'editor_note', 'is_body_camera', 'is_geocoding_exact',\n",
       "       'is_officer_charged', 'lat', 'lon', 'mental', 'name_right', 'photos',\n",
       "       'race_right', 'sources', 'state_right', 'threat_level_display',\n",
       "       'videos', 'weapon', 'charged_bool'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_income = pickle.load(open('df_income_save.p', 'rb'))\n",
    "\n",
    "# pickle.dump(df_police, open( \"df_police_save.p\", \"wb\" ) )\n",
    "# pickle.dump(df_income, open( \"df_income_save.p\", \"wb\" ) )\n",
    "# pickle.dump(df_race, open( \"df_race_save.p\", \"wb\" ) )\n",
    "# pickle.dump(df_latlon, open( \"df_latlon_save.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Zip-City and Zip-Mean CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Median</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>56,663</td>\n",
       "      <td>66,688</td>\n",
       "      <td>16,445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>49,853</td>\n",
       "      <td>75,063</td>\n",
       "      <td>28,069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Zip  Median    Mean     Pop\n",
       "0  1001  56,663  66,688  16,445\n",
       "1  1002  49,853  75,063  28,069"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_income.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_zip_city = pd.read_csv('./zipcodes-by-city.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_zip_city.head(2)\n",
    "df_zip_city_reduced = df_zip_city[['Zipcode','City','State','TotalWages','EstimatedPopulation' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>TotalWages</th>\n",
       "      <th>EstimatedPopulation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704</td>\n",
       "      <td>PARC PARQUE</td>\n",
       "      <td>PR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704</td>\n",
       "      <td>PASEO COSTA DEL SUR</td>\n",
       "      <td>PR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zipcode                 City State  TotalWages  EstimatedPopulation\n",
       "0      704          PARC PARQUE    PR         NaN                  NaN\n",
       "1      704  PASEO COSTA DEL SUR    PR         NaN                  NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zip_city_reduced.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_zip_mean= pd.merge(df_income, df_zip_city_reduced, how='left', left_on='Zip', right_on='Zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>manner_of_death</th>\n",
       "      <th>armed</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>name_right</th>\n",
       "      <th>photos</th>\n",
       "      <th>race_right</th>\n",
       "      <th>sources</th>\n",
       "      <th>state_right</th>\n",
       "      <th>threat_level_display</th>\n",
       "      <th>videos</th>\n",
       "      <th>weapon</th>\n",
       "      <th>charged_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>424</td>\n",
       "      <td>Erick Emmanuel Sanchez</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>shot and Tasered</td>\n",
       "      <td>metal object</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Erick Emmanuel Sanchez</td>\n",
       "      <td>[]</td>\n",
       "      <td>H</td>\n",
       "      <td>[{'source_name': 'El Paso Times.com', 'url': '...</td>\n",
       "      <td>TX</td>\n",
       "      <td>other</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>1113</td>\n",
       "      <td>Chan Leith</td>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>shot</td>\n",
       "      <td>gun</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>CO</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Chan Leith</td>\n",
       "      <td>[]</td>\n",
       "      <td>B</td>\n",
       "      <td>[{'source_name': '9News', 'url': 'http://www.9...</td>\n",
       "      <td>CO</td>\n",
       "      <td>attack</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                    name       date   manner_of_death         armed  \\\n",
       "328   424  Erick Emmanuel Sanchez 2015-04-30  shot and Tasered  metal object   \n",
       "964  1113              Chan Leith 2015-12-21              shot           gun   \n",
       "\n",
       "     age gender race     city state     ...      mental  \\\n",
       "328   22      M    H  El Paso    TX     ...       False   \n",
       "964   25      M    B   Aurora    CO     ...       False   \n",
       "\n",
       "                 name_right photos race_right  \\\n",
       "328  Erick Emmanuel Sanchez     []          H   \n",
       "964              Chan Leith     []          B   \n",
       "\n",
       "                                               sources state_right  \\\n",
       "328  [{'source_name': 'El Paso Times.com', 'url': '...          TX   \n",
       "964  [{'source_name': '9News', 'url': 'http://www.9...          CO   \n",
       "\n",
       "    threat_level_display videos weapon charged_bool  \n",
       "328                other     []   None            0  \n",
       "964               attack     []   None            0  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zip_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>pop</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>totalwages</th>\n",
       "      <th>estimatedpopulation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>56,663</td>\n",
       "      <td>66,688</td>\n",
       "      <td>16,445</td>\n",
       "      <td>1001</td>\n",
       "      <td>AGAWAM</td>\n",
       "      <td>MA</td>\n",
       "      <td>337735143</td>\n",
       "      <td>14021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>49,853</td>\n",
       "      <td>75,063</td>\n",
       "      <td>28,069</td>\n",
       "      <td>1002</td>\n",
       "      <td>AMHERST</td>\n",
       "      <td>MA</td>\n",
       "      <td>415081243</td>\n",
       "      <td>16532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zip  median    mean     pop  zipcode     city state  totalwages  \\\n",
       "0  1001  56,663  66,688  16,445     1001   AGAWAM    MA   337735143   \n",
       "1  1002  49,853  75,063  28,069     1002  AMHERST    MA   415081243   \n",
       "\n",
       "   estimatedpopulation  \n",
       "0                14021  \n",
       "1                16532  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zip_mean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_zip_mean[['city','state']] = df_zip_mean[['city','state']].apply(lambda x: x.str.lower())\n",
    "df[['city','state']] = df[['city','state']].apply(lambda x: x.str.lower())                                  \n",
    "\n",
    "                                   \n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the Above Zip-Mean  Datframe into the original Police Shootings Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_copy = pd.merge(df, df_zip_mean, how='left', on=['city', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tx', 'co', 'md', 'ca', 'fl', 'id', 'az', 'ky', 'al', 'sc', 'ak',\n",
       "       'nj', 'pa', 'wv', 'in', 'wa', 'la', 'wi', 'ks', 'va', 'hi', 'tn',\n",
       "       'oh', 'ny', 'ok', 'mo', 'nv', 'il', 'mn', 'nm', 'ne', 'ma', 'ga',\n",
       "       'ct', 'mi', 'or', 'wy', 'dc', 'nc', 'ut', 'ar', 'mt'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Race of Neighborhood Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_race = pickle.load(open('df_race_save.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Am Indian/Alaskan Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Hawaiian/Pac Islander</th>\n",
       "      <th>Other Race</th>\n",
       "      <th>2+Races%</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>Total.2</th>\n",
       "      <th>White.3</th>\n",
       "      <th>Black.3</th>\n",
       "      <th>Am Indian/Alaskan Native.3</th>\n",
       "      <th>Asian.3</th>\n",
       "      <th>Hawaiian/Pac Islander.3</th>\n",
       "      <th>Other Race.3</th>\n",
       "      <th>2+Races%.3</th>\n",
       "      <th>Hispanic.3</th>\n",
       "      <th>Total.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>79%</td>\n",
       "      <td>7%</td>\n",
       "      <td>1%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>9%</td>\n",
       "      <td>...</td>\n",
       "      <td>100%</td>\n",
       "      <td>38%</td>\n",
       "      <td>10%</td>\n",
       "      <td>1%</td>\n",
       "      <td>5%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>45%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10420</td>\n",
       "      <td>Akron, OH</td>\n",
       "      <td>89%</td>\n",
       "      <td>7%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>1%</td>\n",
       "      <td>...</td>\n",
       "      <td>100%</td>\n",
       "      <td>77%</td>\n",
       "      <td>16%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>3%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS       Name White Black Am Indian/Alaskan Native Asian  \\\n",
       "0    NaN        USA   79%    7%                       1%    3%   \n",
       "1  10420  Akron, OH   89%    7%                       0%    2%   \n",
       "\n",
       "  Hawaiian/Pac Islander Other Race 2+Races% Hispanic   ...   Total.2 White.3  \\\n",
       "0                    0%         0%       2%       9%   ...      100%     38%   \n",
       "1                    0%         0%       1%       1%   ...      100%     77%   \n",
       "\n",
       "  Black.3 Am Indian/Alaskan Native.3 Asian.3 Hawaiian/Pac Islander.3  \\\n",
       "0     10%                         1%      5%                      0%   \n",
       "1     16%                         0%      2%                      0%   \n",
       "\n",
       "  Other Race.3 2+Races%.3 Hispanic.3 Total.3  \n",
       "0           0%         1%        45%    100%  \n",
       "1           0%         2%         3%    100%  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_race.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Racial Composition of Police"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "df_police_div = pd.read_csv('police-locals.csv')\n",
    "df_police_div['city'] = df_police_div['city'].apply(lambda x: x.lower())\n",
    "df_police_div['state']='fpo'\n",
    "df_police_div['state']= df_police_div['city'].apply(lambda x: x.split(',')[-1].strip())\n",
    "df_police_div['city'] = df_police_div['city'].apply(lambda x: x.split(',',1)[0].strip())\n",
    "df_police_div['state'] = df_police_div['state'].apply(lambda x: re.sub('\\.','',x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>police_force_size</th>\n",
       "      <th>all</th>\n",
       "      <th>white</th>\n",
       "      <th>non-white</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>asian</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new york</td>\n",
       "      <td>32300</td>\n",
       "      <td>0.617957</td>\n",
       "      <td>0.446387</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.770891365</td>\n",
       "      <td>0.762860728</td>\n",
       "      <td>0.749235474</td>\n",
       "      <td>new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chicago</td>\n",
       "      <td>12120</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871963</td>\n",
       "      <td>0.877400</td>\n",
       "      <td>0.89740566</td>\n",
       "      <td>0.83982684</td>\n",
       "      <td>0.966666667</td>\n",
       "      <td>chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>los angeles</td>\n",
       "      <td>10100</td>\n",
       "      <td>0.228218</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.263848</td>\n",
       "      <td>0.387387387</td>\n",
       "      <td>0.217679558</td>\n",
       "      <td>0.305263158</td>\n",
       "      <td>los angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washington</td>\n",
       "      <td>9340</td>\n",
       "      <td>0.115632</td>\n",
       "      <td>0.056774</td>\n",
       "      <td>0.157365</td>\n",
       "      <td>0.170189099</td>\n",
       "      <td>0.08988764</td>\n",
       "      <td>0.230769231</td>\n",
       "      <td>washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houston</td>\n",
       "      <td>7700</td>\n",
       "      <td>0.292208</td>\n",
       "      <td>0.173735</td>\n",
       "      <td>0.399258</td>\n",
       "      <td>0.36637931</td>\n",
       "      <td>0.457142857</td>\n",
       "      <td>0.408163265</td>\n",
       "      <td>houston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city  police_force_size       all     white  non-white        black  \\\n",
       "0     new york              32300  0.617957  0.446387   0.764419  0.770891365   \n",
       "1      chicago              12120  0.875000  0.871963   0.877400   0.89740566   \n",
       "2  los angeles              10100  0.228218  0.152778   0.263848  0.387387387   \n",
       "3   washington               9340  0.115632  0.056774   0.157365  0.170189099   \n",
       "4      houston               7700  0.292208  0.173735   0.399258   0.36637931   \n",
       "\n",
       "      hispanic        asian        state  \n",
       "0  0.762860728  0.749235474     new york  \n",
       "1   0.83982684  0.966666667      chicago  \n",
       "2  0.217679558  0.305263158  los angeles  \n",
       "3   0.08988764  0.230769231   washington  \n",
       "4  0.457142857  0.408163265      houston  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_police_div.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The State field is screwed up, make a dictionary and pull the proper value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_abbrev = {\n",
    "'chicago': 'il', 'new york' : 'ny', 'washington' : 'wa', 'houston' : 'tx',\n",
    "'philadelphia': 'pa', 'phoenix' : 'az',  'san diego': 'ca', 'dallas':'tx', 'detroit':'michigan',\n",
    "'san francisco':'ca', 'san antonio' : 'tx', 'atlanta' : 'ga', 'las vegas' : 'nv', 'baltimore' : 'md',\n",
    "'boston' : 'ma', 'fla':'fl', 'texas':'tx', 'ohio':'oh', 'cleveland': 'oh', 'arizona':'az', 'tenn':'tn',\n",
    "'milwaukee': 'wi', 'calif':'ca', 'miami':'fl','denver' : 'co', 'pittsburgh': 'pa' , 'cincinnati':'oh',\n",
    "'ala':'al', 'kan':'ks', 'minneapolis':'mn', 'ore':'or', 'nev':'nv', 'st louis': 'mo', 'miss': 'ms',\n",
    "'wis':'wi', 'colo':'co', 'tucson':'az', 'newark' : 'nj','los angeles':'ca', 'charlotte':'nc', \n",
    "'rochester':'ny','virginia beach':'va', 'albuquerque': 'nm', 'new orleans':'la','louisville':'ky',\n",
    "'norfolk':'va', 'arlington':'ny', 'seattle':'wa', 'indianapolis':'in', 'savannah':'ga', 'oklahoma city':'ok',\n",
    "'jersey city':'nj','baton rouge':'la', 'winston-salem': 'nc', 'jacksonville':'fl','columbus':'oh', 'memphis':'tn',\n",
    "'san jose':'ca', 'birmingham':'al', 'sacramento':'ca', 'raleigh':'nc', 'tampa':'fl',\n",
    " 'santa ana':'ca', 'oakland':'ca', 'orlando':'fl', 'kansas city':'ks', 'nashville':'tn','long beach':'ca',\n",
    "'wichita':'ks', 'fresno':'ca', 'buffalo':'ny', 'portland':'or', 'reno':'nv', 'jackson':'fl',\n",
    "'riverside': 'ca', 'fort lauderdale':'fl', 'st. louis':'mo', 'albany':'ny', 'colorado springs':'co',\n",
    "'toledo': 'oh', 'madison':'wi', 'san bernardino':'ca', 'richmond': 'va', 'detroit':'mi', 'texas':'tx'\n",
    "\n",
    "   }\n",
    "\n",
    "def state_func(df, state_abbrev=state_abbrev):\n",
    "    if df['state'] in state_abbrev:\n",
    "        df['state'] = state_abbrev[df['state']]\n",
    "    elif df['city'] in state_abbrev:\n",
    "        df['state'] = state_abbrev[df['city']]\n",
    "    else:\n",
    "        df['state'] = 'None'\n",
    "    return df\n",
    "        \n",
    "\n",
    "df_police_div = df_police_div.apply(state_func, axis=1)\n",
    "\n",
    "# df_police_div[['city','state']][df_police_div.state=='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>police_force_size</th>\n",
       "      <th>all</th>\n",
       "      <th>white</th>\n",
       "      <th>non-white</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>asian</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new york</td>\n",
       "      <td>32300</td>\n",
       "      <td>0.617957</td>\n",
       "      <td>0.446387</td>\n",
       "      <td>0.764419</td>\n",
       "      <td>0.770891365</td>\n",
       "      <td>0.762860728</td>\n",
       "      <td>0.749235474</td>\n",
       "      <td>ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chicago</td>\n",
       "      <td>12120</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871963</td>\n",
       "      <td>0.877400</td>\n",
       "      <td>0.89740566</td>\n",
       "      <td>0.83982684</td>\n",
       "      <td>0.966666667</td>\n",
       "      <td>il</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city  police_force_size       all     white  non-white        black  \\\n",
       "0  new york              32300  0.617957  0.446387   0.764419  0.770891365   \n",
       "1   chicago              12120  0.875000  0.871963   0.877400   0.89740566   \n",
       "\n",
       "      hispanic        asian state  \n",
       "0  0.762860728  0.749235474    ny  \n",
       "1   0.83982684  0.966666667    il  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_police_div.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_copy = pd.merge(df, df_police_div, how='left', on=['city','state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>manner_of_death</th>\n",
       "      <th>armed</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>totalwages</th>\n",
       "      <th>estimatedpopulation</th>\n",
       "      <th>police_force_size</th>\n",
       "      <th>all</th>\n",
       "      <th>white</th>\n",
       "      <th>non-white</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>424</td>\n",
       "      <td>Erick Emmanuel Sanchez</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>shot and Tasered</td>\n",
       "      <td>metal object</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>el paso</td>\n",
       "      <td>tx</td>\n",
       "      <td>...</td>\n",
       "      <td>79901</td>\n",
       "      <td>91447915</td>\n",
       "      <td>12682</td>\n",
       "      <td>2260</td>\n",
       "      <td>0.85177</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.861027</td>\n",
       "      <td>**</td>\n",
       "      <td>0.86102719</td>\n",
       "      <td>**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>424</td>\n",
       "      <td>Erick Emmanuel Sanchez</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>shot and Tasered</td>\n",
       "      <td>metal object</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>el paso</td>\n",
       "      <td>tx</td>\n",
       "      <td>...</td>\n",
       "      <td>79902</td>\n",
       "      <td>270117955</td>\n",
       "      <td>16056</td>\n",
       "      <td>2260</td>\n",
       "      <td>0.85177</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.861027</td>\n",
       "      <td>**</td>\n",
       "      <td>0.86102719</td>\n",
       "      <td>**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>424</td>\n",
       "      <td>Erick Emmanuel Sanchez</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>shot and Tasered</td>\n",
       "      <td>metal object</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>el paso</td>\n",
       "      <td>tx</td>\n",
       "      <td>...</td>\n",
       "      <td>79903</td>\n",
       "      <td>163746053</td>\n",
       "      <td>14072</td>\n",
       "      <td>2260</td>\n",
       "      <td>0.85177</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.861027</td>\n",
       "      <td>**</td>\n",
       "      <td>0.86102719</td>\n",
       "      <td>**</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                    name       date   manner_of_death         armed  \\\n",
       "0  424  Erick Emmanuel Sanchez 2015-04-30  shot and Tasered  metal object   \n",
       "1  424  Erick Emmanuel Sanchez 2015-04-30  shot and Tasered  metal object   \n",
       "2  424  Erick Emmanuel Sanchez 2015-04-30  shot and Tasered  metal object   \n",
       "\n",
       "   age gender race     city state  ...  zipcode totalwages  \\\n",
       "0   22      M    H  el paso    tx  ...    79901   91447915   \n",
       "1   22      M    H  el paso    tx  ...    79902  270117955   \n",
       "2   22      M    H  el paso    tx  ...    79903  163746053   \n",
       "\n",
       "  estimatedpopulation police_force_size      all     white non-white black  \\\n",
       "0               12682              2260  0.85177  0.826446  0.861027    **   \n",
       "1               16056              2260  0.85177  0.826446  0.861027    **   \n",
       "2               14072              2260  0.85177  0.826446  0.861027    **   \n",
       "\n",
       "     hispanic asian  \n",
       "0  0.86102719    **  \n",
       "1  0.86102719    **  \n",
       "2  0.86102719    **  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Racial Composition of Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_neighborhoor_race = pickle.load(open('df_race_save.p', 'rb'))\n",
    "df_neighborhoor_race['State'] = df_neighborhoor_race['Name'].apply(lambda x: x.split(',')[-1].strip())\n",
    "df_neighborhoor_race['City'] = df_neighborhoor_race['Name'].apply(lambda x: x.split(',')[0].strip())\n",
    "df_neighborhoor_race['State'] = df_neighborhoor_race['State'].apply(lambda x: re.sub('\\.','',x).strip())\n",
    "df_neighborhoor_race['State'] = df_neighborhoor_race['State'].apply(lambda x: x.lower())\n",
    "df_neighborhoor_race['City'] = df_neighborhoor_race['City'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Am Indian/Alaskan Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Hawaiian/Pac Islander</th>\n",
       "      <th>Other Race</th>\n",
       "      <th>2+Races%</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>Black.3</th>\n",
       "      <th>Am Indian/Alaskan Native.3</th>\n",
       "      <th>Asian.3</th>\n",
       "      <th>Hawaiian/Pac Islander.3</th>\n",
       "      <th>Other Race.3</th>\n",
       "      <th>2+Races%.3</th>\n",
       "      <th>Hispanic.3</th>\n",
       "      <th>Total.3</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>79%</td>\n",
       "      <td>7%</td>\n",
       "      <td>1%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>9%</td>\n",
       "      <td>...</td>\n",
       "      <td>10%</td>\n",
       "      <td>1%</td>\n",
       "      <td>5%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>45%</td>\n",
       "      <td>100%</td>\n",
       "      <td>usa</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10420</td>\n",
       "      <td>Akron, OH</td>\n",
       "      <td>89%</td>\n",
       "      <td>7%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>1%</td>\n",
       "      <td>...</td>\n",
       "      <td>16%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>3%</td>\n",
       "      <td>100%</td>\n",
       "      <td>oh</td>\n",
       "      <td>akron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10580</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>88%</td>\n",
       "      <td>4%</td>\n",
       "      <td>0%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>3%</td>\n",
       "      <td>...</td>\n",
       "      <td>15%</td>\n",
       "      <td>0%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>2%</td>\n",
       "      <td>7%</td>\n",
       "      <td>100%</td>\n",
       "      <td>ny</td>\n",
       "      <td>albany-schenectady-troy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10740</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>53%</td>\n",
       "      <td>2%</td>\n",
       "      <td>4%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>37%</td>\n",
       "      <td>...</td>\n",
       "      <td>3%</td>\n",
       "      <td>4%</td>\n",
       "      <td>1%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>54%</td>\n",
       "      <td>100%</td>\n",
       "      <td>nm</td>\n",
       "      <td>albuquerque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10900</td>\n",
       "      <td>Allentown-Bethlehem-Easton, PA-NJ</td>\n",
       "      <td>86%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>8%</td>\n",
       "      <td>...</td>\n",
       "      <td>8%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>32%</td>\n",
       "      <td>100%</td>\n",
       "      <td>pa-nj</td>\n",
       "      <td>allentown-bethlehem-easton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS                               Name White Black  \\\n",
       "0    NaN                                USA   79%    7%   \n",
       "1  10420                          Akron, OH   89%    7%   \n",
       "2  10580        Albany-Schenectady-Troy, NY   88%    4%   \n",
       "3  10740                    Albuquerque, NM   53%    2%   \n",
       "4  10900  Allentown-Bethlehem-Easton, PA-NJ   86%    3%   \n",
       "\n",
       "  Am Indian/Alaskan Native Asian Hawaiian/Pac Islander Other Race 2+Races%  \\\n",
       "0                       1%    3%                    0%         0%       2%   \n",
       "1                       0%    2%                    0%         0%       1%   \n",
       "2                       0%    3%                    0%         0%       1%   \n",
       "3                       4%    2%                    0%         0%       2%   \n",
       "4                       0%    2%                    0%         0%       1%   \n",
       "\n",
       "  Hispanic             ...             Black.3 Am Indian/Alaskan Native.3  \\\n",
       "0       9%             ...                 10%                         1%   \n",
       "1       1%             ...                 16%                         0%   \n",
       "2       3%             ...                 15%                         0%   \n",
       "3      37%             ...                  3%                         4%   \n",
       "4       8%             ...                  8%                         0%   \n",
       "\n",
       "  Asian.3 Hawaiian/Pac Islander.3 Other Race.3 2+Races%.3 Hispanic.3 Total.3  \\\n",
       "0      5%                      0%           0%         1%        45%    100%   \n",
       "1      2%                      0%           0%         2%         3%    100%   \n",
       "2      3%                      0%           1%         2%         7%    100%   \n",
       "3      1%                      0%           0%         1%        54%    100%   \n",
       "4      2%                      0%           0%         2%        32%    100%   \n",
       "\n",
       "   State                        City  \n",
       "0    usa                         usa  \n",
       "1     oh                       akron  \n",
       "2     ny     albany-schenectady-troy  \n",
       "3     nm                 albuquerque  \n",
       "4  pa-nj  allentown-bethlehem-easton  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neighborhoor_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_nh_race = df_neighborhoor_race[['City','State','White', 'Black', 'Am Indian/Alaskan Native', 'Asian',\n",
    "       'Hawaiian/Pac Islander', 'Other Race', '2+Races%', 'Hispanic', 'Total',\n",
    "       'White.1', 'Black.1', 'Am Indian/Alaskan Native.1', 'Asian.1',\n",
    "       'Hawaiian/Pac Islander.1', 'Other Race.1', '2+Races%.1', 'Hispanic.1',\n",
    "       'Total.1', 'White.2', 'Black.2', 'Am Indian/Alaskan Native.2',\n",
    "       'Asian.2', 'Hawaiian/Pac Islander.2', 'Other Race.2', '2+Races%.2',\n",
    "       'Hispanic.2', 'Total.2', 'White.3', 'Black.3',\n",
    "       'Am Indian/Alaskan Native.3', 'Asian.3', 'Hawaiian/Pac Islander.3',\n",
    "       'Other Race.3', '2+Races%.3', 'Hispanic.3', 'Total.3']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/pandas/core/frame.py:2697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_nh_race.rename(columns = {\n",
    "        \"White\": \"W_White\",# NEIGHBORHOOD OF AVERAGE WHITE\n",
    "        \"Black\": \"W_Black\",\n",
    "        \"Am Indian/Alaskan Native\": \"W_Ind_Inuit\",\n",
    "        \"Asian\": \"W_Asian\",\n",
    "        \"Hawaiian/Pac Islander\": \"W_PIslander\",\n",
    "        \"Other Race\": \"W_Other\",\n",
    "        \"2+Races%\":'W_Mixed',\n",
    "        \"Hispanic\":\"W_Hispanic\",\n",
    "        \"Total\": \"W_Total\",\n",
    "        \"White.1\": \"B_White\",# NEIGHBORHOOD OF AVERAGE BLACK\n",
    "        \"Black.1\": \"B_Black\",\n",
    "        \"Am Indian/Alaskan Native.1\": \"B_Ind_Inuit\",\n",
    "        \"Asian.1\": \"B_Asian\",\n",
    "        \"Hawaiian/Pac Islander.1\": \"B_PIslander\",\n",
    "        \"Other Race.1\": \"B_Other\",\n",
    "        \"2+Races%.1\":'B_Mixed',\n",
    "        \"Hispanic.1\":\"B_Hispanic\",\n",
    "        \"Total.1\": \"B_Total\",      \n",
    "        \"White.2\": \"A_White\",# NEIGHBORHOOD OF AVERAGE ASIAN \n",
    "        \"Black.2\": \"A_Black\",\n",
    "        \"Am Indian/Alaskan Native.2\": \"A_Ind_Inuit\",\n",
    "        \"Asian.2\": \"A_Asian\",\n",
    "        \"Hawaiian/Pac Islander.2\": \"A_PIslander\",\n",
    "        \"Other Race.2\": \"A_Other\",\n",
    "        \"2+Races%.2\":'A_Mixed',\n",
    "        \"Hispanic.2\":\"A_Hispanic\",\n",
    "        \"Total.2\": \"A_Total\",      \n",
    "        \"White.3\": \"H_White\",# NEIGHBORHOOD OF AVERAGE Hispanic \n",
    "        \"Black.3\": \"H_Black\",\n",
    "        \"Am Indian/Alaskan Native.3\": \"H_Ind_Inuit\",\n",
    "        \"Asian.3\": \"H_Asian\",\n",
    "        \"Hawaiian/Pac Islander.3\": \"H_PIslander\",\n",
    "        \"Other Race.3\": \"H_Other\",\n",
    "        \"2+Races%.3\":'H_Mixed',\n",
    "        \"Hispanic.3\":\"H_Hispanic\",\n",
    "        \"Total.3\":\"H_Total\"  \n",
    "        }, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df_nh_race['Cities']=df_nh_race.City.apply(lambda x: x.strip().split('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>W_White</th>\n",
       "      <th>W_Black</th>\n",
       "      <th>W_Ind_Inuit</th>\n",
       "      <th>W_Asian</th>\n",
       "      <th>W_PIslander</th>\n",
       "      <th>W_Other</th>\n",
       "      <th>W_Mixed</th>\n",
       "      <th>W_Hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>H_White</th>\n",
       "      <th>H_Black</th>\n",
       "      <th>H_Ind_Inuit</th>\n",
       "      <th>H_Asian</th>\n",
       "      <th>H_PIslander</th>\n",
       "      <th>H_Other</th>\n",
       "      <th>H_Mixed</th>\n",
       "      <th>H_Hispanic</th>\n",
       "      <th>H_Total</th>\n",
       "      <th>Cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usa</td>\n",
       "      <td>usa</td>\n",
       "      <td>79%</td>\n",
       "      <td>7%</td>\n",
       "      <td>1%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>9%</td>\n",
       "      <td>...</td>\n",
       "      <td>38%</td>\n",
       "      <td>10%</td>\n",
       "      <td>1%</td>\n",
       "      <td>5%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>45%</td>\n",
       "      <td>100%</td>\n",
       "      <td>[usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akron</td>\n",
       "      <td>oh</td>\n",
       "      <td>89%</td>\n",
       "      <td>7%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>1%</td>\n",
       "      <td>...</td>\n",
       "      <td>77%</td>\n",
       "      <td>16%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>3%</td>\n",
       "      <td>100%</td>\n",
       "      <td>[akron]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albany-schenectady-troy</td>\n",
       "      <td>ny</td>\n",
       "      <td>88%</td>\n",
       "      <td>4%</td>\n",
       "      <td>0%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>3%</td>\n",
       "      <td>...</td>\n",
       "      <td>71%</td>\n",
       "      <td>15%</td>\n",
       "      <td>0%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>2%</td>\n",
       "      <td>7%</td>\n",
       "      <td>100%</td>\n",
       "      <td>[albany, schenectady, troy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albuquerque</td>\n",
       "      <td>nm</td>\n",
       "      <td>53%</td>\n",
       "      <td>2%</td>\n",
       "      <td>4%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>37%</td>\n",
       "      <td>...</td>\n",
       "      <td>36%</td>\n",
       "      <td>3%</td>\n",
       "      <td>4%</td>\n",
       "      <td>1%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>54%</td>\n",
       "      <td>100%</td>\n",
       "      <td>[albuquerque]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allentown-bethlehem-easton</td>\n",
       "      <td>pa-nj</td>\n",
       "      <td>86%</td>\n",
       "      <td>3%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>1%</td>\n",
       "      <td>8%</td>\n",
       "      <td>...</td>\n",
       "      <td>57%</td>\n",
       "      <td>8%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2%</td>\n",
       "      <td>32%</td>\n",
       "      <td>100%</td>\n",
       "      <td>[allentown, bethlehem, easton]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         City  State W_White W_Black W_Ind_Inuit W_Asian  \\\n",
       "0                         usa    usa     79%      7%          1%      3%   \n",
       "1                       akron     oh     89%      7%          0%      2%   \n",
       "2     albany-schenectady-troy     ny     88%      4%          0%      3%   \n",
       "3                 albuquerque     nm     53%      2%          4%      2%   \n",
       "4  allentown-bethlehem-easton  pa-nj     86%      3%          0%      2%   \n",
       "\n",
       "  W_PIslander W_Other W_Mixed W_Hispanic               ...                \\\n",
       "0          0%      0%      2%         9%               ...                 \n",
       "1          0%      0%      1%         1%               ...                 \n",
       "2          0%      0%      1%         3%               ...                 \n",
       "3          0%      0%      2%        37%               ...                 \n",
       "4          0%      0%      1%         8%               ...                 \n",
       "\n",
       "  H_White H_Black H_Ind_Inuit H_Asian H_PIslander H_Other H_Mixed H_Hispanic  \\\n",
       "0     38%     10%          1%      5%          0%      0%      1%        45%   \n",
       "1     77%     16%          0%      2%          0%      0%      2%         3%   \n",
       "2     71%     15%          0%      3%          0%      1%      2%         7%   \n",
       "3     36%      3%          4%      1%          0%      0%      1%        54%   \n",
       "4     57%      8%          0%      2%          0%      0%      2%        32%   \n",
       "\n",
       "  H_Total                          Cities  \n",
       "0    100%                           [usa]  \n",
       "1    100%                         [akron]  \n",
       "2    100%     [albany, schenectady, troy]  \n",
       "3    100%                   [albuquerque]  \n",
       "4    100%  [allentown, bethlehem, easton]  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nh_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_nh_race_copy = df_nh_race.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "(\"unhashable type: 'list'\", 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-351-5507727c411c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#df_nh_race.City.value_counts()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdf_nh_race_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_nh_race\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   3970\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3972\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3973\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3974\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4064\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4065\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4066\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-351-5507727c411c>\u001b[0m in \u001b[0;36mget_zip\u001b[0;34m(race_df, df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrace_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrace_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcities\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mrace_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zipcode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zipcode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrace_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;34m\"\"\"True if the key is in the info axis \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/index.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;31m# work around some kind of odd cython bug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: (\"unhashable type: 'list'\", 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "def get_zip(race_df, df= df):  \n",
    "    cities = race_df['Cities']\n",
    "    if cities in df['city']: \n",
    "        race_df['zipcode'] = df['zipcode'][0] \n",
    "        return race_df\n",
    "#     for i in race_df['Cities']: \n",
    "#         #print(cities)\n",
    "#         Eif not df['city'][df['city'] == i].empty:\n",
    "#             race_df['zipcode'] = df['zipcode'][0]   \n",
    "\n",
    "\n",
    "            \n",
    "#df_police_div = df_police_div.apply(state_func, axis=1)\n",
    "        \n",
    "# def state_func(df, state_abbrev=state_abbrev):\n",
    "#     if df['state'] in state_abbrev:\n",
    "#         df['state'] = state_abbrev[df['state']]\n",
    "#     elif df['city'] in state_abbrev:\n",
    "#         df['state'] = state_abbrev[df['city']]\n",
    "#     else:\n",
    "#         df['state'] = 'None'\n",
    "#     return df\n",
    "                    \n",
    "    \n",
    "    #get_zip(['el paso', 'austin', 'houston'], df) \n",
    "\n",
    "\n",
    "\n",
    "#pd.notnull(df.zipcode[df.city=='el paso'][0])\n",
    "#df_nh_race.City.value_counts()\n",
    "\n",
    "df_nh_race_copy = df_nh_race.apply(get_zip, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A_Asian', 'A_Black', 'A_Hispanic', 'A_Ind_Inuit', 'A_Mixed', 'A_Other',\n",
       "       'A_PIslander', 'A_Total', 'A_White', 'B_Asian', 'B_Black', 'B_Hispanic',\n",
       "       'B_Ind_Inuit', 'B_Mixed', 'B_Other', 'B_PIslander', 'B_Total',\n",
       "       'B_White', 'Cities', 'City', 'H_Asian', 'H_Black', 'H_Hispanic',\n",
       "       'H_Ind_Inuit', 'H_Mixed', 'H_Other', 'H_PIslander', 'H_Total',\n",
       "       'H_White', 'State', 'W_Asian', 'W_Black', 'W_Hispanic', 'W_Ind_Inuit',\n",
       "       'W_Mixed', 'W_Other', 'W_PIslander', 'W_Total', 'W_White', 'zipcode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nh_race_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " pickle.dump(df, open( \"df_big_table_save.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
